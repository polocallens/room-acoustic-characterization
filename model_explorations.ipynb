{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.config.experimental.set_visible_devices([], 'GPU')\n",
    "\n",
    "\n",
    "from keras.layers import Permute\n",
    "from keras.layers import Conv1D, MaxPooling1D\n",
    "from keras.layers.recurrent import GRU, LSTM\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow import keras\n",
    "\n",
    "\n",
    "#from keras.models import Sequential, Model\n",
    "#from keras.layers import Dense, Dropout, Activation, Flatten, CuDNNLSTM, BatchNormalization\n",
    "#from keras.layers import Convolution2D, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "#from keras.layers import Input, Reshape, TimeDistributed\n",
    "\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "\n",
    "\n",
    "def CRNN2D(X_shape, nb_classes):\n",
    "    '''\n",
    "    Model used for evaluation in paper. Inspired by K. Choi model in:\n",
    "    https://github.com/keunwoochoi/music-auto_tagging-keras/blob/master/music_tagger_crnn.py\n",
    "    '''\n",
    "\n",
    "    nb_layers = 4  # number of convolutional layers\n",
    "    nb_filters = [64, 128, 128, 128]  # filter sizes\n",
    "    kernel_size = (3, 3)  # convolution kernel size\n",
    "    activation = 'elu'  # activation function to use after each layer\n",
    "    pool_size = [(2, 2), (4, 2), (4, 2), (4, 2),\n",
    "                 (4, 2)]  # size of pooling area\n",
    "\n",
    "    # shape of input data (frequency, time, channels)\n",
    "    input_shape = (X_shape[1], X_shape[2], X_shape[3])\n",
    "    frequency_axis = 1\n",
    "    time_axis = 2\n",
    "    channel_axis = 3\n",
    "\n",
    "    # Create sequential model and normalize along frequency axis\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(BatchNormalization(axis=frequency_axis, input_shape=input_shape))\n",
    "   \n",
    "    # First convolution layer specifies shape\n",
    "    model.add(Conv2D(nb_filters[0], kernel_size=kernel_size, padding='same',\n",
    "                     data_format=\"channels_last\",\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size[0], strides=pool_size[0],))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Add more convolutional layers\n",
    "    for layer in range(nb_layers - 1):\n",
    "        # Convolutional layer\n",
    "        model.add(Conv2D(nb_filters[layer + 1], kernel_size=kernel_size,\n",
    "                         padding='same'))\n",
    "        model.add(Activation(activation))\n",
    "        model.add(BatchNormalization(\n",
    "            axis=channel_axis))  # Improves overfitting/underfitting\n",
    "        model.add(MaxPooling2D(pool_size=pool_size[layer + 1],\n",
    "                               strides=pool_size[layer + 1],\n",
    "                              data_format=\"channels_first\"))  # Max pooling\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "        # Reshaping input for recurrent layer\n",
    "    # (frequency, time, channels) --> (time, frequency, channel)\n",
    "    model.add(Permute((time_axis, frequency_axis, channel_axis)))\n",
    "    resize_shape = model.output_shape[2] * model.output_shape[3]\n",
    "    model.add(Reshape((model.output_shape[1], resize_shape)))\n",
    "\n",
    "    # recurrent layer\n",
    "    model.add(GRU(32, return_sequences=True))\n",
    "    model.add(GRU(32, return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    return model\n",
    "\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "\n",
    "def CRNN2D_parallel(X_shape, nb_classes):\n",
    "    '''\n",
    "    Model used for evaluation in paper. Inspired by K. Choi model in:\n",
    "    https://github.com/keunwoochoi/music-auto_tagging-keras/blob/master/music_tagger_crnn.py\n",
    "    '''\n",
    "\n",
    "    nb_layers = 4  # number of convolutional layers\n",
    "    nb_filters = [64, 128, 128, 128]  # filter sizes\n",
    "    kernel_size = (3, 3)  # convolution kernel size\n",
    "    activation = 'elu'  # activation function to use after each layer\n",
    "    pool_size = [(2, 2), (4, 2), (4, 2), (4, 2),\n",
    "                 (4, 2)]  # size of pooling area\n",
    "\n",
    "    # shape of input data (frequency, time, channels)\n",
    "    input_shape = (X_shape[1], X_shape[2], X_shape[3])\n",
    "    frequency_axis = 1\n",
    "    time_axis = 2\n",
    "    channel_axis = 3\n",
    "\n",
    "    # Create sequential model and normalize along frequency axis\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(BatchNormalization(axis=frequency_axis, input_shape=input_shape))\n",
    "   \n",
    "    # First convolution layer specifies shape\n",
    "    model.add(Conv2D(nb_filters[0], kernel_size=kernel_size, padding='same',\n",
    "                     data_format=\"channels_last\",\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size[0], strides=pool_size[0],))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Add more convolutional layers\n",
    "    for layer in range(nb_layers - 1):\n",
    "        # Convolutional layer\n",
    "        model.add(Conv2D(nb_filters[layer + 1], kernel_size=kernel_size,\n",
    "                         padding='same'))\n",
    "        model.add(Activation(activation))\n",
    "        model.add(BatchNormalization(\n",
    "            axis=channel_axis))  # Improves overfitting/underfitting\n",
    "        model.add(MaxPooling2D(pool_size=pool_size[layer + 1],\n",
    "                               strides=pool_size[layer + 1],\n",
    "                              data_format=\"channels_first\"))  # Max pooling\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "        # Reshaping input for recurrent layer\n",
    "    # (frequency, time, channels) --> (time, frequency, channel)\n",
    "    model.add(Permute((time_axis, frequency_axis, channel_axis)))\n",
    "    resize_shape = model.output_shape[2] * model.output_shape[3]\n",
    "    model.add(Reshape((model.output_shape[1], resize_shape)))\n",
    "\n",
    "    # recurrent layer\n",
    "    model.add(GRU(32, return_sequences=True))\n",
    "    model.add(GRU(32, return_sequences=False))\n",
    "    model.add(Dropout(0.3))\n",
    "\n",
    "    # Output layer\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    return model\n",
    "\n",
    "#---------------------------------------------------------------------------------\n",
    "def CNN(X_shape, nb_classes):\n",
    "\n",
    "    nb_layers = 4  # number of convolutional layers\n",
    "    nb_filters = [64, 128, 128, 128]  # filter sizes\n",
    "    kernel_size = (3, 3)  # convolution kernel size\n",
    "    activation = 'elu'  # activation function to use after each layer\n",
    "    pool_size = [(2, 2), (4, 2), (4, 2), (4, 2),\n",
    "                 (4, 2)]  # size of pooling area\n",
    "\n",
    "    # shape of input data (frequency, time, channels)\n",
    "    input_shape = (X_shape[1], X_shape[2], X_shape[3])\n",
    "    frequency_axis = 1\n",
    "    time_axis = 2\n",
    "    channel_axis = 3\n",
    "\n",
    "    # Create sequential model and normalize along frequency axis\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(BatchNormalization(axis=frequency_axis, input_shape=input_shape))\n",
    "   \n",
    "    # First convolution layer specifies shape\n",
    "    model.add(Conv2D(nb_filters[0], kernel_size=kernel_size, padding='same',\n",
    "                     data_format=\"channels_last\",\n",
    "                     input_shape=input_shape))\n",
    "    model.add(Activation(activation))\n",
    "    model.add(BatchNormalization(axis=channel_axis))\n",
    "    model.add(MaxPooling2D(pool_size=pool_size[0], strides=pool_size[0],))\n",
    "    model.add(Dropout(0.1))\n",
    "\n",
    "    # Add more convolutional layers\n",
    "    for layer in range(nb_layers - 1):\n",
    "        # Convolutional layer\n",
    "        model.add(Conv2D(nb_filters[layer + 1], kernel_size=kernel_size,\n",
    "                         padding='same'))\n",
    "        model.add(Activation(activation))\n",
    "        model.add(BatchNormalization(\n",
    "            axis=channel_axis))  # Improves overfitting/underfitting\n",
    "        model.add(MaxPooling2D(pool_size=pool_size[layer + 1],\n",
    "                               strides=pool_size[layer + 1],\n",
    "                              data_format=\"channels_first\"))  # Max pooling\n",
    "        model.add(Dropout(0.1))\n",
    "\n",
    "        # Reshaping input for recurrent layer\n",
    "    # (frequency, time, channels) --> (time, frequency, channel)\n",
    "    \"\"\"model.add(Permute((time_axis, frequency_axis, channel_axis)))\n",
    "    resize_shape = model.output_shape[2] * model.output_shape[3]\n",
    "    model.add(Reshape((model.output_shape[1], resize_shape)))\n",
    "\n",
    "    # recurrent layer\n",
    "    model.add(GRU(32, return_sequences=True))\n",
    "    model.add(GRU(32, return_sequences=False))\n",
    "    model.add(Dropout(0.3))\"\"\"\n",
    "\n",
    "    #Dense layers\n",
    "    model.add(Dense(64))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    model.add(Dense(32))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    model.add(Dropout(0.2))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(nb_classes))\n",
    "    model.add(Activation(\"relu\"))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = CNN((None,40, 645 ,2), 12)\n",
    "\n",
    "#Setup optimizer\n",
    "opt = keras.optimizers.Adam(learning_rate=0.001)\n",
    "model.compile(loss='mean_squared_error', optimizer = opt) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "batch_normalization_5 (Batch (None, 40, 645, 2)        160       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 40, 645, 64)       1216      \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 40, 645, 64)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 40, 645, 64)       256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 20, 322, 64)       0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 20, 322, 64)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 20, 322, 128)      73856     \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 20, 322, 128)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 20, 322, 128)      512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 20, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 20, 80, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 20, 80, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 20, 80, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 20, 80, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 20, 20, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 20, 20, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 20, 20, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 20, 20, 128)       512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 20, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 20, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20, 5, 64)         4160      \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 20, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 20, 5, 64)         0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20, 5, 32)         2080      \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 20, 5, 32)         0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 20, 5, 32)         0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 20, 5, 12)         396       \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 20, 5, 12)         0         \n",
      "=================================================================\n",
      "Total params: 231,372\n",
      "Trainable params: 230,396\n",
      "Non-trainable params: 976\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (kerasenv)",
   "language": "python",
   "name": "kerasenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
